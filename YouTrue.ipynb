{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1Rl0LCpZZYYy+DdhGN82s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EduardoComparato/YouTrue/blob/main/YouTrue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GTXsaAi1zlAM"
      },
      "outputs": [],
      "source": [
        "# Instalar Frameworks\n",
        "!pip install -q google-adk google-genai youtube-transcript-api gradio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Verifica se a chave de API já está definida no ambiente\n",
        "# Se não estiver, tenta obter do userdata do Colab\n",
        "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
        "    try:\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao obter GOOGLE_API_KEY do userdata: {e}\")\n",
        "        print(\"Por favor, certifique-se de que a chave 'GOOGLE_API_KEY' está definida nos Secrets do Colab.\")\n",
        "        # Se não conseguir obter, o código pode falhar posteriormente ao usar a API"
      ],
      "metadata": {
        "id": "vn53kDAvLbMV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o cliente da SDK do Gemini\n",
        "# Adicionado um bloco try-except caso a chave de API não esteja disponível\n",
        "try:\n",
        "    from google import genai\n",
        "    client = genai.Client()\n",
        "    MODEL_ID = \"gemini-2.0-flash\"\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao configurar o cliente Gemini: {e}\")\n",
        "    print(\"Verifique se sua GOOGLE_API_KEY está correta e acessível.\")\n",
        "    client = None # Define client como None para evitar erros posteriores"
      ],
      "metadata": {
        "id": "2zn9rHFWLj8f"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pergunta ao Gemini uma informação mais recente que seu conhecimento\n",
        "\n",
        "from IPython.display import HTML, Markdown"
      ],
      "metadata": {
        "id": "jOux1E1ZLr-8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import google_search\n",
        "from google.genai import types  # Para criar conteúdos (Content e Part)\n",
        "from datetime import date\n",
        "import textwrap # Para formatar melhor a saída de texto\n",
        "from IPython.display import display, Markdown # Para exibir texto formatado no Colab\n",
        "import requests # Para fazer requisições HTTP\n",
        "import warnings\n",
        "import gradio as gr # Para criar a interface gráfica\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "6jHXDRQ6MM-0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from typing import Optional\n",
        "\n",
        "# Função auxiliar que envia uma mensagem para um agente via Runner e retorna a resposta final\n",
        "def call_agent(agent: Agent, message_text: str, user_id: Optional[str] = None, session_id: Optional[str] = None) -> str:\n",
        "    # Verifica se o cliente Gemini foi inicializado com sucesso\n",
        "    if client is None:\n",
        "        return \"Erro: Cliente Gemini não inicializado. Verifique sua chave de API.\"\n",
        "\n",
        "    # Cria um serviço de sessão em memória\n",
        "    session_service = InMemorySessionService()\n",
        "\n",
        "    # Gera user_id e session_id se não forem fornecidos\n",
        "    user_id_to_use = user_id if user_id else str(uuid.uuid4())\n",
        "    session_id_to_use = session_id if session_id else str(uuid.uuid4())\n",
        "    # Cria uma nova sessão (você pode personalizar os IDs conforme necessário)\n",
        "    session = session_service.create_session(app_name=agent.name, user_id=user_id_to_use, session_id=session_id_to_use)\n",
        "    # Cria um Runner para o agente\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    # Cria o conteúdo da mensagem de entrada\n",
        "    # Mantido a criação de Content e Part conforme o código original do usuário\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
        "\n",
        "    final_response = \"\"\n",
        "# Itera assincronamente pelos eventos retornados durante a execução do agente\n",
        "    try:\n",
        "        for event in runner.run(user_id=user_id_to_use, session_id=session_id_to_use, new_message=content):\n",
        "            if event.is_final_response():\n",
        "              if event.content is not None:\n",
        "                for part in event.content.parts:\n",
        "                  if part.text is not None:\n",
        "                   final_response += part.text\n",
        "                   final_response += \"\\n\"\n",
        "    except Exception as e:\n",
        "        return f\"Erro durante a execução do agente {agent.name}: {e}\"\n",
        "\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "TatLDC0VMXuy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  # Função mantida, o output será usado diretamente no componente Gradio Markdown\n",
        "  text = text.replace('•', '  *')\n",
        "  return text # Retorna a string formatada em Markdown"
      ],
      "metadata": {
        "id": "rPUgQ8EeO0KJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Transcritor de Vídeos --- #\n",
        "##########################################\n",
        "def API_transcritor(ID_digitado):\n",
        "  try:\n",
        "    from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled\n",
        "\n",
        "    ytt_api = YouTubeTranscriptApi()\n",
        "    transcricao = ytt_api.fetch(ID_digitado, languages=['pt-BR', 'en-US', 'pt', 'en','es'])\n",
        "\n",
        "    return transcricao\n",
        "  except NoTranscriptFound:\n",
        "        print(f\"No transcript found for video ID: {ID_digitado} in the specified languages or any other language.\")\n",
        "        return None\n",
        "  except TranscriptsDisabled:\n",
        "        print(f\"Transcripts are disabled for video ID: {ID_digitado}.\")\n",
        "        return None\n",
        "  except Exception as e:\n",
        "        print(f\"An error occurred while fetching the transcript for video ID {ID_digitado}: {e}\")\n",
        "        return None\n",
        "  except TranscriptsDisabled:\n",
        "        print(f\"Transcripts are disabled for video ID: {ID_digitado}.\")\n",
        "        return None\n",
        "  except Exception as e:\n",
        "        print(f\"An error occurred while fetching the transcript for video ID {ID_digitado}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "lzxCkq10PyNW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 1: Informações do vídeo --- #\n",
        "################################################\n",
        "# Verifica se a chave de API do YouTube está definida\n",
        "YOUTUBE_API_KEY = userdata.get(\"YOUTUBE_API_KEY\")\n",
        "youtube = None # Inicializa youtube como None\n",
        "if YOUTUBE_API_KEY:\n",
        "    try:\n",
        "        from googleapiclient.discovery import build\n",
        "        youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao construir o cliente da API do YouTube: {e}\")\n",
        "        print(\"Verifique se sua YOUTUBE_API_KEY está correta.\")\n",
        "\n",
        "\n",
        "def agente_informativo(ID_digitado):\n",
        "    # Verifica se o cliente YouTube foi inicializado com sucesso\n",
        "    if youtube is None:\n",
        "        return \"Erro: Cliente da API do YouTube não inicializado. Verifique sua chave de API do YouTube.\"\n",
        "\n",
        "    try:\n",
        "        request = youtube.videos().list(\n",
        "            part=\"snippet,contentDetails\",\n",
        "            id=ID_digitado\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        if response and 'items' in response and response['items']:\n",
        "            video_info = response['items'][0]\n",
        "            title = video_info['snippet']['title']\n",
        "            duration = video_info['contentDetails']['duration']\n",
        "            thumbnail = video_info['snippet']['thumbnails']['high']['url']\n",
        "\n",
        "            # Formata as informações para uma string amigável\n",
        "            info_string = f\"Título: {title}\\n\"\n",
        "            info_string += f\"Duração: {duration}\\n\"\n",
        "            info_string += f\"Thumbnail: {thumbnail}\\n\"\n",
        "\n",
        "            return info_string\n",
        "        else:\n",
        "            return \"Vídeo não encontrado ou informações indisponíveis.\"\n",
        "    except Exception as e:\n",
        "        return f\"Ocorreu um erro ao buscar as informações do vídeo: {e}\""
      ],
      "metadata": {
        "id": "7PToxqFpE-Bs"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 2: Revisor de texto --- #\n",
        "################################################\n",
        "# Define o agente revisor fora da função principal para que seja criado apenas uma vez\n",
        "revisor = Agent(\n",
        "    name=\"agente_revisor\",\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    instruction=\"\"\"\n",
        "    Você é um revisor de texto. Quero que pegue o texto mais recente fornecido pelo transcritor e retire elementos de minutagem e tópico,\n",
        "    somente deixando o texto, separando em parágrafos ou não somente conforme for necessário. Caso o texto esteja em outra língua,\n",
        "    sem ser o português. Traduza para o português.\n",
        "    \"\"\",\n",
        "    description=\"Agente que revisa textos\",\n",
        ")\n",
        "\n",
        "def agente_revisor_call(transcricao):\n",
        "    if not transcricao or \"Erro:\" in transcricao: # Não chama o agente se a transcrição for vazia ou contiver erro\n",
        "        return \"Não foi possível revisar o texto devido a um problema na transcrição.\"\n",
        "    entrada_do_agente_revisor = f\"Texto a ser revisado: {transcricao}\"\n",
        "    # Executa o agente\n",
        "    texto_revisado = call_agent(revisor, entrada_do_agente_revisor)\n",
        "    return texto_revisado\n"
      ],
      "metadata": {
        "id": "Occhr0IzU4Pk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################\n",
        "# --- Agente 3: Buscador e Primeiro Verificador --- #\n",
        "######################################\n",
        "# Define o agente buscador fora da função principal para que seja criado apenas uma vez\n",
        "buscador = Agent(\n",
        "    name=\"agente_buscador\",\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    instruction=\"\"\"\n",
        "        Você é um buscador de fontes informacionais. A partir do texto fornecido pelo revisor,\n",
        "        detecte o tema e pontos abordados e procure sobre em, NO MÁXIMO, 20 fontes confiáveis e\n",
        "        de relevância no tema, onde as informações sejam por texto\n",
        "        (evitando artigos de opinião e fontes muito imparciais).\n",
        "        Enfatize, nessas fontes, as partes onde ocorram incongruências entre informações do texto e das fontes.\n",
        "        Ao final, forneça os links das fontes pesquisadas.\n",
        "        \"\"\",\n",
        "    description=\"Agente que busca fontes relacionadas e faz uma primeira comparação\",\n",
        "    tools=[google_search]\n",
        ")\n",
        "\n",
        "def agente_buscador_call(texto_revisado):\n",
        "    if not texto_revisado or \"Erro:\" in texto_revisado or \"Não foi possível revisar\" in texto_revisado: # Não chama o agente se o texto revisado for vazio ou contiver erro\n",
        "         return \"Não foi possível realizar a busca e comparação devido a um problema na revisão do texto.\"\n",
        "    entrada_do_agente_buscador = f\"Texto revisado: {texto_revisado}\"\n",
        "    # Executa o agente\n",
        "    busca_comparada = call_agent(buscador, entrada_do_agente_buscador)\n",
        "    return busca_comparada"
      ],
      "metadata": {
        "id": "VZJx1jFTcA08"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 4: Aponta-erros --- #\n",
        "##########################################\n",
        "# Define o agente de erros fora da função principal para que seja criado apenas uma vez\n",
        "erros = Agent(\n",
        "    name=\"agente_erros\",\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    instruction=\"\"\"\n",
        "        Você aponta os erros de uma fonte informacional, tendo como base um texto e uma análise subsequente\n",
        "        constando links de fontes confiáveis. Quero que vasculhe essas fontes, para confirmar se não há informações erradas no texto original.\n",
        "\n",
        "\n",
        "        ###\n",
        "\n",
        "\n",
        "        Com a análise de erros pronta, indique os trechos que estão errados, o porquê de estarem errados, e uma correção para tais trechos.\n",
        "        Para cada correção, aponte a fonte que está sendo utilizada. Ao fim, indique a porcentagem do quanto o conteúdo do texto original estava\n",
        "        comprometido por erros de informação.\n",
        "\n",
        "\n",
        "        ###\n",
        "\n",
        "\n",
        "        Ao fim, indique a confiabilidade do texto original a partir de 5 níveis, indicados por emojis,\n",
        "        levando em consideração a porcentagem estabelecida anteriormente. Especifique quais as porcentagens levadas em conta na análise.\n",
        "\n",
        "        Grau de confiabilidade:\n",
        "\n",
        "        Confiável (0% a 7% de erros) -> 🟢\n",
        "\n",
        "        Bom (8% a 20%) -> 🔵\n",
        "\n",
        "        Mediano (20% a 45%) -> 🟡\n",
        "\n",
        "        Ruim (46% a 60%) -> 🟠\n",
        "\n",
        "        Grave (61% a 100%) -> 🔴\n",
        "\n",
        "        ###\n",
        "\n",
        "        Caso o texto final esteja em inglês, passe para o português.\n",
        "        \"\"\",\n",
        "    description=\"Agente que aponta erros, correções e grau de confiabilidade.\",\n",
        "    tools=[google_search]\n",
        ")\n",
        "\n",
        "def agente_erros_call(texto_revisado, busca_comparada):\n",
        "    if not busca_comparada or \"Erro:\" in busca_comparada or \"Não foi possível realizar a busca\" in busca_comparada: # Não chama o agente se a busca for vazia ou contiver erro\n",
        "        return \"Não foi possível analisar os erros devido a um problema na busca e comparação.\"\n",
        "    entrada_do_agente_erros = f\"Texto original: {texto_revisado}, Buscador: {busca_comparada}\"\n",
        "    # Executa o agente\n",
        "    texto_corrigido = call_agent(erros, entrada_do_agente_erros)\n",
        "    return texto_corrigido"
      ],
      "metadata": {
        "id": "4v5HYygfc_qF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Função principal que será chamada pelo Gradio ---\n",
        "def processar_entrada(tipo_analise, conteudo_entrada):\n",
        "    \"\"\"\n",
        "    Processa a entrada do usuário (ID de vídeo ou texto) usando a cadeia de agentes.\n",
        "\n",
        "    Args:\n",
        "        tipo_analise (str): O tipo de análise escolhido ('ID' ou 'Texto Completo').\n",
        "        conteudo_entrada (str): O ID do vídeo ou o texto completo a ser analisado.\n",
        "\n",
        "    Retorna:\n",
        "        tuple: Uma tupla contendo os resultados de cada etapa do processo para exibição no Gradio.\n",
        "               (info_video_str, transcricao_str, texto_revisado_str, busca_comparada_str, texto_corrigido_str)\n",
        "    \"\"\"\n",
        "    info_video_str = \"\"\n",
        "    transcricao_str = \"\"\n",
        "    texto_revisado_str = \"\"\n",
        "    busca_comparada_str = \"\"\n",
        "    texto_corrigido_str = \"\"\n",
        "\n",
        "    if not conteudo_entrada:\n",
        "        return (\"Por favor, insira um ID de vídeo ou texto para analisar.\", \"\", \"\", \"\", \"\")\n",
        "\n",
        "    if tipo_analise == \"ID\":\n",
        "        ID_digitado = conteudo_entrada\n",
        "        info_video_str = agente_informativo(ID_digitado)\n",
        "        transcricao_str = API_transcritor(ID_digitado)\n",
        "\n",
        "        if \"Erro:\" in transcricao_str or \"Não foi possível obter a transcrição\" in transcricao_str or \"Erro inesperado\" in transcricao_str:\n",
        "             texto_revisado_str = \"Processamento interrompido devido a erro na transcrição.\"\n",
        "             busca_comparada_str = \"Processamento interrompido devido a erro na transcrição.\"\n",
        "             texto_corrigido_str = \"Processamento interrompido devido a erro na transcrição.\"\n",
        "        else:\n",
        "            texto_revisado_str = agente_revisor_call(transcricao_str)\n",
        "            if \"Erro:\" in texto_revisado_str or \"Não foi possível revisar\" in texto_revisado_str:\n",
        "                 busca_comparada_str = \"Processamento interrompido devido a erro na revisão.\"\n",
        "                 texto_corrigido_str = \"Processamento interrompido devido a erro na revisão.\"\n",
        "            else:\n",
        "                busca_comparada_str = agente_buscador_call(texto_revisado_str)\n",
        "                if \"Erro:\" in busca_comparada_str or \"Não foi possível realizar a busca\" in busca_comparada_str:\n",
        "                     texto_corrigido_str = \"Processamento interrompido devido a erro na busca.\"\n",
        "                else:\n",
        "                     texto_corrigido_str = agente_erros_call(texto_revisado_str, busca_comparada_str)\n",
        "\n",
        "\n",
        "    elif tipo_analise == \"Texto Completo\":\n",
        "        texto_completo = conteudo_entrada\n",
        "        transcricao_str = texto_completo # Neste caso, a \"transcrição\" é o texto fornecido\n",
        "\n",
        "        texto_revisado_str = agente_revisor_call(transcricao_str)\n",
        "        if \"Erro:\" in texto_revisado_str or \"Não foi possível revisar\" in texto_revisado_str:\n",
        "             busca_comparada_str = \"Processamento interrompido devido a erro na revisão.\"\n",
        "             texto_corrigido_str = \"Processamento interrompido devido a erro na revisão.\"\n",
        "        else:\n",
        "            busca_comparada_str = agente_buscador_call(texto_revisado_str)\n",
        "            if \"Erro:\" in busca_comparada_str or \"Não foi possível realizar a busca\" in busca_comparada_str:\n",
        "                 texto_corrigido_str = \"Processamento interrompido devido a erro na busca.\"\n",
        "            else:\n",
        "                 texto_corrigido_str = agente_erros_call(texto_revisado_str, busca_comparada_str)\n",
        "\n",
        "\n",
        "    # Aplica a formatação markdown aos resultados que se beneficiam dela\n",
        "    texto_revisado_str = to_markdown(texto_revisado_str)\n",
        "    busca_comparada_str = to_markdown(busca_comparada_str)\n",
        "    texto_corrigido_str = to_markdown(texto_corrigido_str)\n",
        "\n",
        "\n",
        "    return info_video_str, transcricao_str, texto_revisado_str, busca_comparada_str, texto_corrigido_str"
      ],
      "metadata": {
        "id": "GaWgVZoRR8ph"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Criação da Interface Gradio ---\n",
        "\n",
        "# Define os componentes de entrada\n",
        "input_components = [\n",
        "    gr.Radio([\"ID\", \"Texto Completo\"], label=\"Tipo de Análise\", value=\"ID\"), # Valor padrão é ID\n",
        "    gr.Textbox(label=\"Insira o ID do YouTube ou o Texto Completo\")\n",
        "]\n",
        "\n",
        "# Define os componentes de saída para cada etapa do processo\n",
        "output_components = [\n",
        "    gr.Textbox(label=\"Informações do Vídeo (se ID)\", interactive=False),\n",
        "    gr.Textbox(label=\"Transcrição Original / Texto Fornecido\", interactive=False),\n",
        "    gr.Markdown(label=\"Texto Revisado pelo Agente 2\"), # Usa Markdown para formatação\n",
        "    gr.Markdown(label=\"Busca e Comparação pelo Agente 3\"), # Usa Markdown para formatação\n",
        "    gr.Markdown(label=\"Análise de Erros e Confiabilidade pelo Agente 4\") # Usa Markdown para formatação\n",
        "]"
      ],
      "metadata": {
        "id": "_hoBDC2KSEbb"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria a interface Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=processar_entrada, # Função Python a ser executada\n",
        "    inputs=input_components, # Componentes de entrada\n",
        "    outputs=output_components, # Componentes de saída\n",
        "    title=\"YouTrue - Verificador de Informações\",\n",
        "    description=\"Analise vídeos do YouTube (via ID) ou textos completos para verificar informações usando uma cadeia de Agentes Gemini.\",\n",
        "    allow_flagging=\"never\" # Desabilita a opção de \"flagging\" padrão do Gradio\n",
        ")"
      ],
      "metadata": {
        "id": "l9GN4cb5StDP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lança a interface Gradio\n",
        "# No Google Colab, isso irá gerar um link público\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "4Wxo0LzOSupL",
        "outputId": "9b3e146f-5f23-4019-ac67-344453fcd61a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://da849ee0280992e4d8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://da849ee0280992e4d8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://da849ee0280992e4d8.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}